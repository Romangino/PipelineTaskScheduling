At my job as a bioinformatics research assistant, one of my responsibilities is pipeline development. Most modern biological experiments generate a lot of raw data, often through genomic sequencing, which requires many separate processing steps to become usuable information. As the human genome contains over 3 billion base pairs, raw sequencing files can be massive and take hours to complete each step, even on a powerful server. Although a single sequencing run might contain only 6-12 samples, there is also the situation when a data processing pipeline is updated or modified, and hundreds or even thousands of samples may need to be rerun. In this case optimization becomes a very interesting topic. Because scheduling problems can be very challenging computationally, heuristic approaches are commonly used. In particular, genetic algorithms can be used to find approximate solutions to infeasible optimization problems. I am really interested in this idea, because in the real world problems can become complex very quickly, and greedy or dynamic programming solutions may not be suitable. The idea of using the natural process of evolution as the inspiration for an algorithm is fascinating to me, and as an aspiring computational biologist, genetic algorithms feel like something I should have in my toolbox. Exploring this problem will provide a framework to estimate, analyze, and optimize the runtime of multistep pipelines on a set of input files, allowing my lab to make the best use of the hardware we have and saving valuable time.
